{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c921154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"ProfitAndLoss.json\") as f:\n",
    "    rawdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_col(data):\n",
    "    \"\"\"\n",
    "    Find the data.\n",
    "    \"\"\"\n",
    "    ## \n",
    "    # abstract normalizing for each column case\n",
    "    ##\n",
    "    global child_count\n",
    "    if isinstance(data, pandas.core.frame.DataFrame): # check if already normalized to df\n",
    "        if 'type' in data and data['type'] == 'data': # will always be coldata, always df \n",
    "            # iterate through rows\n",
    "            for row in data.shape[0]:\n",
    "                try:\n",
    "                    row_norm = pd.json_normalize(data['ColData'][row])\n",
    "                    acc_name = row_norm['value'][0]\n",
    "                    acc_id   = row_norm['id'][0]\n",
    "                    acc_val  = row_norm['value'][1]\n",
    "                    child_count += 1\n",
    "                    \n",
    "                    ##### add all of these to df, list, dict??\n",
    "                except:\n",
    "                    pass\n",
    "        elif 'Header.ColData' in data:\n",
    "            for row in data.shape[0]:\n",
    "                try:\n",
    "                    row_norm = pd.json_normalize(data['Header.ColData'][row])\n",
    "                    if isinstance(row_norm, pandas.core.frame.DataFrame) and 'id' not in row_norm:\n",
    "                        continue\n",
    "                    elif isinstance(row_norm, pandas.core.frame.DataFrame): \n",
    "                        acc_name = row_norm['value'][0]\n",
    "                        acc_id   = row_norm['id'][0]\n",
    "                        acc_val  = row_norm['value'][1]\n",
    "                        df       = pd.DataFrame([acc_name, acc_id, acc_val],\n",
    "                                               columns=['AccountName',\n",
    "                                                       'AccountID',\n",
    "                                                       'AccountValue'])\n",
    "                    # it if is just one row with account value\n",
    "                    elif isinstance(row_norm, pandas.core.series.Series):\n",
    "                        acc_name = row_norm['value'][0]\n",
    "                        acc_id   = row_norm['id'][0]\n",
    "                        acc_val  = row_norm['value'][1]\n",
    "                        df       = pd.DataFrame([acc_name, acc_id, acc_val],\n",
    "                                               columns=['AccountName',\n",
    "                                                       'AccountID',\n",
    "                                                       'AccountValue'])\n",
    "                        # add row_norm['value'] to df, list, dict?\n",
    "                except:\n",
    "                    continue\n",
    "            elif \n",
    "                # if it is just one row with account name                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128754f",
   "metadata": {},
   "source": [
    "if you find another level of nesting, just concat what you just did with a bigger list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a566239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(data):\n",
    "    \"\"\"\n",
    "    Find the data.\n",
    "    \"\"\"\n",
    "    global child_count\n",
    "    if isinstance(data, dict):\n",
    "        data = pd.json_normalize(data)\n",
    "        parse_json(data)\n",
    "    elif isinstance(data, pandas.core.frame.DataFrame):\n",
    "        for row in data.shape[0]:\n",
    "            try:\n",
    "                row_norm = pd.json_normalize(data['Rows.Row'][row])\n",
    "                if 'Rows.Row' in row_norm: # and isinstance(row_norm, pandas.core.frame.DataFrame):\n",
    "                    parse_json(row_norm)\n",
    "            except:\n",
    "                continue\n",
    "        if 'type' in data and data['type'] == 'data': # will always be coldata, always df \n",
    "            # iterate through rows\n",
    "            for row in data.shape[0]:\n",
    "                try:\n",
    "                    row_norm = pd.json_normalize(data['ColData'][row])\n",
    "                    acc_name = row_norm['value'][0]\n",
    "                    acc_id   = row_norm['id'][0]\n",
    "                    acc_val  = row_norm['value'][1]\n",
    "                    child_count += 1\n",
    "                    \n",
    "                    ##### add all of these to df, list, dict??\n",
    "                except:\n",
    "                    pass\n",
    "        elif 'Header.ColData' in data:\n",
    "            for row in data.shape[0]:\n",
    "                try:\n",
    "                    row_norm = pd.json_normalize(data['Header.ColData'][row])\n",
    "                    if isinstance(row_norm, pandas.core.frame.DataFrame) and 'id' not in row_norm:\n",
    "                        continue\n",
    "                    elif isinstance(row_norm, pandas.core.frame.DataFrame): \n",
    "                        acc_name = row_norm['value'][0]\n",
    "                        acc_id   = row_norm['id'][0]\n",
    "                        acc_val  = row_norm['value'][1]\n",
    "                        df       = pd.DataFrame([acc_name, acc_id, acc_val],\n",
    "                                               columns=['AccountName',\n",
    "                                                       'AccountID',\n",
    "                                                       'AccountValue'])\n",
    "                    # it if is just one row with account value\n",
    "                    elif isinstance(row_norm, pandas.core.series.Series):\n",
    "                        acc_name = row_norm['value'][0]\n",
    "                        acc_id   = row_norm['id'][0]\n",
    "                        acc_val  = row_norm['value'][1]\n",
    "                        df       = pd.DataFrame([acc_name, acc_id, acc_val],\n",
    "                                               columns=['AccountName',\n",
    "                                                       'AccountID',\n",
    "                                                       'AccountValue'])\n",
    "                        # add row_norm['value'] to df, list, dict?\n",
    "                except:\n",
    "                    continue\n",
    "            elif \n",
    "                # if it is just one row with account name                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18b7c20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c753868c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header.Time</th>\n",
       "      <th>Header.ReportName</th>\n",
       "      <th>Header.DateMacro</th>\n",
       "      <th>Header.ReportBasis</th>\n",
       "      <th>Header.StartPeriod</th>\n",
       "      <th>Header.EndPeriod</th>\n",
       "      <th>Header.SummarizeColumnsBy</th>\n",
       "      <th>Header.Currency</th>\n",
       "      <th>Header.Option</th>\n",
       "      <th>Columns.Column</th>\n",
       "      <th>Rows.Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-07T12:55:08-07:00</td>\n",
       "      <td>ProfitAndLoss</td>\n",
       "      <td>this fiscal year-to-date</td>\n",
       "      <td>Accrual</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>Total</td>\n",
       "      <td>USD</td>\n",
       "      <td>[{'Name': 'AccountingStandard', 'Value': 'GAAP...</td>\n",
       "      <td>[{'ColTitle': '', 'ColType': 'Account', 'MetaD...</td>\n",
       "      <td>[{'Header': {'ColData': [{'value': 'Income'}, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Header.Time Header.ReportName          Header.DateMacro  \\\n",
       "0  2021-06-07T12:55:08-07:00     ProfitAndLoss  this fiscal year-to-date   \n",
       "\n",
       "  Header.ReportBasis Header.StartPeriod Header.EndPeriod  \\\n",
       "0            Accrual         2020-07-01       2021-06-07   \n",
       "\n",
       "  Header.SummarizeColumnsBy Header.Currency  \\\n",
       "0                     Total             USD   \n",
       "\n",
       "                                       Header.Option  \\\n",
       "0  [{'Name': 'AccountingStandard', 'Value': 'GAAP...   \n",
       "\n",
       "                                      Columns.Column  \\\n",
       "0  [{'ColTitle': '', 'ColType': 'Account', 'MetaD...   \n",
       "\n",
       "                                            Rows.Row  \n",
       "0  [{'Header': {'ColData': [{'value': 'Income'}, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_0 = pd.json_normalize(rawdata)\n",
    "child_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8015369",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b3dae4a8cdda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchild_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "child_0.to_json()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nests(rawdata):\n",
    "    try:\n",
    "        norm_data = pd.json_normalize(rawdata)\n",
    "    except AttributeError:\n",
    "        norm_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a08d8",
   "metadata": {},
   "source": [
    "## something i found online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e15720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_extract(obj, key):\n",
    "    \"\"\"Recursively fetch values from nested JSON.\"\"\"\n",
    "    arr = []\n",
    "\n",
    "    def extract(obj, arr, key):\n",
    "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    extract(v, arr, key)\n",
    "                elif k == key:\n",
    "                    arr.append(v)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract(item, arr, key)\n",
    "        return arr\n",
    "\n",
    "    values = extract(obj, arr, key)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fea40541",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = json_extract(rawdata, ('value'))\n",
    "while(\"\" in values) :\n",
    "         values.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95d1f188",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2f14c482431f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;34m'Income'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "while('Total' in values) :\n",
    "    values.remove('Total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc01a1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['107', '108', '278', '279', '692', '406', '109', '281', '280', '110', '111', '112', '558', '282', '369', '392', '698', '648', '28', '29', '284', '30', '285', '31', '33', '35', '419', '658', '612', '36', '37', '387', '595', '630', '39', '304', '358', '388', '596', '678', '456', '650', '40', '41', '42', '43', '44', '147', '148', '45', '149', '150', '460', '464', '154', '155', '263', '508', '509', '156', '157', '634', '159', '312', '391', '638', '576', '672', '397', '580', '396', '639', '577', '690', '578', '640', '579', '673', '641', '163', '164', '165', '186', '166', '189', '568', '581', '167', '169', '170', '561', '688', '562', '563', '187', '46', '47', '48', '49', '50', '51', '185', '52', '386', '420', '53', '162', '54', '56', '57', '58', '60', '61', '62', '59', '63', '64', '65', '66', '67', '68', '69', '70', '71', '115', '116', '117', '118', '370', '372', '119', '378', '120', '121', '123', '126', '129', '130', '127', '131', '132', '133', '134', '144', '253', '254', '145', '146', '390', '72', '135', '140', '142', '138', '141', '139', '137', '379', '143', '311', '361', '75', '220', '79', '226', '516', '227', '424', '225', '421', '247', '422', '547', '248', '80', '81', '87', '82', '83', '86', '84', '85', '88', '89', '90', '218', '297', '92', '204', '205', '206', '207', '427', '76', '223', '221', '160', '249', '430', '431', '73', '77', '212', '213', '517', '699', '702', '582', '616', '250', '426', '542', '543', '544', '545', '555', '251', '171', '172', '178', '174', '177', '175', '176', '179', '180', '181', '296', '183', '193', '637', '309', '210', '566', '661', '594', '627', '628', '629', '238', '512', '515', '554', '557']\n"
     ]
    }
   ],
   "source": [
    "ids = json_extract(rawdata, ('id'))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe18e398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids) == len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e8c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
