{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "import json\r\n",
    "import re\r\n",
    "\r\n",
    "transaction_list_path = \"C:\\\\Users\\\\paulcassidy\\\\OneDrive - Archdiocese of Chicago\\\\Documents\\\\JSON_Parsing\\\\RawData\\\\TransactionList.json\"\r\n",
    "general_ledger_path   = \"C:\\\\Users\\\\paulcassidy\\\\OneDrive - Archdiocese of Chicago\\\\Documents\\\\JSON_Parsing\\\\RawData\\\\GeneralLedger.json\"\r\n",
    "\r\n",
    "with open(transaction_list_path) as f:\r\n",
    "    transaction_list = json.load(f)\r\n",
    "\r\n",
    "with open(general_ledger_path) as f:\r\n",
    "    general_ledger = json.load(f)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def parse_record_gl(data):\r\n",
    "    \"\"\"\r\n",
    "    Iterate through ColData or Header.ColData data frame. \r\n",
    "    Check what kind of data each data frame contains.\r\n",
    "    Parse each record in data frame accordingly and return values.\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # regular expression matching date format\r\n",
    "    rex = re.compile(\"^[0-9]{4}-[0-9]{2}-[0-9]{2}$\")\r\n",
    "\r\n",
    "    # check which ColData data frame is being parsed\r\n",
    "    for row in range(data.shape[0]):\r\n",
    "        # transaction detail data frame\r\n",
    "        if re.search(rex, data['value'][0]):\r\n",
    "            td   = data['value'][0]\r\n",
    "            tt   = data['value'][1]\r\n",
    "            ttid = data['id'][1]\r\n",
    "            dn   = data['value'][2]\r\n",
    "            vn   = data['value'][3]\r\n",
    "            vid  = data['id'][3]\r\n",
    "            m    = data['value'][4]\r\n",
    "            s    = data['value'][5]\r\n",
    "            sid  = data['id'][5]\r\n",
    "            ta   = data['value'][6]\r\n",
    "            nab  = data['value'][7]\r\n",
    "            \r\n",
    "            vals = {\r\n",
    "                'TransactionDate' : td,\r\n",
    "                'TransactionType' : tt,\r\n",
    "                'TransactionTypeID' : ttid,\r\n",
    "                'DocumentNumber' : dn,\r\n",
    "                'VendorName' : vn,\r\n",
    "                'VendorID' : vid,\r\n",
    "                'Memo' : m,\r\n",
    "                'Split' : s,\r\n",
    "                'SplitID' : sid,\r\n",
    "                'TransactionAmount' : ta,\r\n",
    "                'NewAccountBalance' : nab\r\n",
    "            }\r\n",
    "\r\n",
    "            # replace missing values           \r\n",
    "            for k in vals:\r\n",
    "                if not vals[k]:\r\n",
    "                    vals[k] = \"NA\"\r\n",
    "            \r\n",
    "            return vals\r\n",
    "\r\n",
    "        # beginning balance data frame\r\n",
    "        elif data['value'][0] == \"Beginning Balance\":\r\n",
    "            bb   = data['value'][7]\r\n",
    "            return {\r\n",
    "                'BeginningBalance' : bb\r\n",
    "            }\r\n",
    "\r\n",
    "        # name data frame\r\n",
    "        else:\r\n",
    "            if 'id' in data:\r\n",
    "                an  = data['value'][0]\r\n",
    "                aid = data['id'][0]\r\n",
    "            else:\r\n",
    "                an  = data['value'][0]\r\n",
    "                aid = \"NA\"\r\n",
    "                \r\n",
    "            return {\r\n",
    "                'AccountName' : an,\r\n",
    "                'AccountID' : aid\r\n",
    "            } \r\n",
    "\r\n",
    "def json_crawler_gl(data):\r\n",
    "    # If data is dictionary returned by json.load(), then flatten it to initial pandas data frame\r\n",
    "    if isinstance(data, dict):\r\n",
    "        data = pd.json_normalize(data)\r\n",
    "        return_value = json_crawler_gl_tl(data)\r\n",
    "        return return_value \r\n",
    "    \r\n",
    "    # Crawl through JSON file, normalizing by different keys to find account data and save to lst\r\n",
    "    else:\r\n",
    "        # Initialize list to hold account data objects\r\n",
    "        lst = []\r\n",
    "        acct_names = []\r\n",
    "        \r\n",
    "        for row in range(data.shape[0]):\r\n",
    "            # Normalize by 'ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['ColData'][row])\r\n",
    "                lst.append(parse_record_gl(record_data))\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Header.ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['Header.ColData'][row])\r\n",
    "                lst.append(parse_record_gl(record_data))\r\n",
    "                # acct_names.append(\r\n",
    "                #     {'AccountName' : parse_record_gl_tl(record_data)['AccountName']},\r\n",
    "                #     {'AccountID' : parse_record_gl_tl(record_data)['AccountID']})\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Rows.Row'\r\n",
    "            try:\r\n",
    "                row_data = pd.json_normalize(data['Rows.Row'][row])\r\n",
    "                # Capture lst and return value before recursive function call\r\n",
    "                return_value = json_crawler_gl(row_data)\r\n",
    "                lst = lst + return_value\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "\r\n",
    "        return lst\r\n",
    "\r\n",
    "def list_df_csv(lst, prefix, filename):\r\n",
    "    df = pd.DataFrame(lst)\r\n",
    "    df.to_csv(f\"{prefix}/{filename}.csv\", index = False)\r\n",
    "\r\n",
    "def parse_record_tl(data):\r\n",
    "    \"\"\"\r\n",
    "    Iterate through ColData or Header.ColData data frame. \r\n",
    "    Check what kind of data each data frame contains.\r\n",
    "    Parse each record in data frame accordingly and return values.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # regular expression matching date format\r\n",
    "    rex = re.compile(\"^[0-9]{4}-[0-9]{2}-[0-9]{2}$\")\r\n",
    "\r\n",
    "    # check which ColData data frame is being parsed\r\n",
    "    for row in range(data.shape[0]):\r\n",
    "        # transaction detail data frame\r\n",
    "        if re.search(rex, data['value'][0]):\r\n",
    "            td   = data['value'][0]\r\n",
    "            tt   = data['value'][1]\r\n",
    "            ttid = data['id'][1]\r\n",
    "            dn   = data['value'][2]\r\n",
    "            p    = data['value'][3]\r\n",
    "            vn   = data['value'][4]\r\n",
    "            vid  = data['id'][4]\r\n",
    "            m    = data['value'][5]\r\n",
    "            s    = data['value'][6]\r\n",
    "            sid  = data['id'][6]\r\n",
    "            ta   = data['value'][7]\r\n",
    "            \r\n",
    "            vals = {\r\n",
    "                'TransactionDate' : td,\r\n",
    "                'TransactionType' : tt,\r\n",
    "                'TransactionTypeID' : ttid,\r\n",
    "                'DocumentNumber' : dn,\r\n",
    "                'Posting' : p,\r\n",
    "                'VendorName' : vn,\r\n",
    "                'VendorID' : vid,\r\n",
    "                'Memo' : m,\r\n",
    "                'Split' : s,\r\n",
    "                'SplitID' : sid,\r\n",
    "                'TransactionAmount' : ta\r\n",
    "                }\r\n",
    "\r\n",
    "            # replace missing values           \r\n",
    "            for k in vals:\r\n",
    "                if not vals[k]:\r\n",
    "                    vals[k] = \"NA\"\r\n",
    "            \r\n",
    "            return vals\r\n",
    "\r\n",
    "def json_crawler_tl(data):\r\n",
    "    # If data is dictionary returned by json.load(), then flatten it to initial pandas data frame\r\n",
    "    if isinstance(data, dict):\r\n",
    "        data = pd.json_normalize(data)\r\n",
    "        return_value = json_crawler_tl(data)\r\n",
    "        return return_value \r\n",
    "    \r\n",
    "    # Crawl through JSON file, normalizing by different keys to find account data and save to lst\r\n",
    "    else:\r\n",
    "        # Initialize list to hold account data objects\r\n",
    "        lst = []\r\n",
    "        acct_names = []\r\n",
    "        \r\n",
    "        for row in range(data.shape[0]):\r\n",
    "            # Normalize by 'ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['ColData'][row])\r\n",
    "                lst.append(parse_record_tl(record_data))\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Header.ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['Header.ColData'][row])\r\n",
    "                lst.append(parse_record_tl(record_data))\r\n",
    "                # acct_names.append(\r\n",
    "                #     {'AccountName' : parse_record_gl_tl(record_data)['AccountName']},\r\n",
    "                #     {'AccountID' : parse_record_gl_tl(record_data)['AccountID']})\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Rows.Row'\r\n",
    "            try:\r\n",
    "                row_data = pd.json_normalize(data['Rows.Row'][row])\r\n",
    "                # Capture lst and return value before recursive function call\r\n",
    "                return_value = json_crawler_tl(row_data)\r\n",
    "                lst = lst + return_value\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "\r\n",
    "        return lst\r\n",
    "\r\n",
    "def list_df_csv(lst, prefix, filename):\r\n",
    "    df = pd.DataFrame(lst)\r\n",
    "    df.to_csv(f\"{prefix}/{filename}.csv\", index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# We need a way to store AccountName and AccountID and add them to the same object that the account detail and beginning balance goes in.\r\n",
    "# We also need to impute AccountCategory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "count = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def parse_record_gl(data):\r\n",
    "    \"\"\"\r\n",
    "    Iterate through ColData or Header.ColData data frame. \r\n",
    "    Check what kind of data each data frame contains.\r\n",
    "    Parse each record in data frame accordingly and return values.\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # regular expression matching date format\r\n",
    "    rex = re.compile(\"^[0-9]{4}-[0-9]{2}-[0-9]{2}$\")\r\n",
    "\r\n",
    "    # check which ColData data frame is being parsed\r\n",
    "    for row in range(data.shape[0]):\r\n",
    "        # transaction detail data frame\r\n",
    "        if re.search(rex, data['value'][0]):\r\n",
    "            td   = data['value'][0]\r\n",
    "            tt   = data['value'][1]\r\n",
    "            ttid = data['id'][1]\r\n",
    "            dn   = data['value'][2]\r\n",
    "            vn   = data['value'][3]\r\n",
    "            vid  = data['id'][3]\r\n",
    "            m    = data['value'][4]\r\n",
    "            s    = data['value'][5]\r\n",
    "            sid  = data['id'][5]\r\n",
    "            ta   = data['value'][6]\r\n",
    "            nab  = data['value'][7]\r\n",
    "            \r\n",
    "            vals = {\r\n",
    "                'TransactionDate' : td,\r\n",
    "                'TransactionType' : tt,\r\n",
    "                'TransactionTypeID' : ttid,\r\n",
    "                'DocumentNumber' : dn,\r\n",
    "                'VendorName' : vn,\r\n",
    "                'VendorID' : vid,\r\n",
    "                'Memo' : m,\r\n",
    "                'Split' : s,\r\n",
    "                'SplitID' : sid,\r\n",
    "                'TransactionAmount' : ta,\r\n",
    "                'NewAccountBalance' : nab\r\n",
    "            }\r\n",
    "\r\n",
    "            # replace missing values           \r\n",
    "            for k in vals:\r\n",
    "                if not vals[k]:\r\n",
    "                    vals[k] = \"NA\"\r\n",
    "            \r\n",
    "            return vals\r\n",
    "\r\n",
    "        # beginning balance data frame\r\n",
    "        elif data['value'][0] == \"Beginning Balance\":\r\n",
    "            bb   = data['value'][7]\r\n",
    "            return {\r\n",
    "                'BeginningBalance' : bb\r\n",
    "            }\r\n",
    "\r\n",
    "        # name data frame\r\n",
    "        else:\r\n",
    "            if 'id' in data:\r\n",
    "                an  = data['value'][0]\r\n",
    "                aid = data['id'][0]\r\n",
    "            else:\r\n",
    "                an  = data['value'][0]\r\n",
    "                aid = \"NA\"\r\n",
    "                \r\n",
    "            return {\r\n",
    "                'AccountName' : an,\r\n",
    "                'AccountID' : aid\r\n",
    "            } \r\n",
    "\r\n",
    "def json_crawler_gl(data):\r\n",
    "    # initialize global COUNT\r\n",
    "    global count\r\n",
    "\r\n",
    "    # If data is dictionary returned by json.load(), then flatten it to initial pandas data frame\r\n",
    "    if isinstance(data, dict):\r\n",
    "        data = pd.json_normalize(data)\r\n",
    "        return_value = json_crawler_gl_tl(data)\r\n",
    "        return return_value \r\n",
    "    \r\n",
    "    # Crawl through JSON file, normalizing by different keys to find account data and save to lst\r\n",
    "    else:\r\n",
    "        # Initialize list to hold account data objects\r\n",
    "        lst = []\r\n",
    "        acct_names = []\r\n",
    "        \r\n",
    "        for row in range(data.shape[0]):\r\n",
    "            # Normalize by 'ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['ColData'][row])\r\n",
    "                lst.append(parse_record_gl(record_data))\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Header.ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['Header.ColData'][row])\r\n",
    "                lst.append(parse_record_gl(record_data))\r\n",
    "                count += 1\r\n",
    "                # acct_names.append(\r\n",
    "                #     {'AccountName' : parse_record_gl_tl(record_data)['AccountName']},\r\n",
    "                #     {'AccountID' : parse_record_gl_tl(record_data)['AccountID']})\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Rows.Row'\r\n",
    "            try:\r\n",
    "                row_data = pd.json_normalize(data['Rows.Row'][row])\r\n",
    "                # Capture lst and return value before recursive function call\r\n",
    "                return_value = json_crawler_gl(row_data)\r\n",
    "                lst = lst + return_value\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "\r\n",
    "        return lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Account Names and IDs only come in the `Header.ColData` object. We can leverage that."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Can you append to a dictionary within a list??"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "lst = [{'foo' : 'bar', 'fizz' : 'buzz', 'par' : 'birdie'}]\r\n",
    "new_obj = {'boom' : 'pow'}\r\n",
    "\r\n",
    "lst[0].update(new_obj)\r\n",
    "print(lst)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'foo': 'bar', 'fizz': 'buzz', 'par': 'birdie', 'boom': 'pow'}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "yes you can\r\n",
    "new change on line 89 below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def parse_record_gl(data):\r\n",
    "    \"\"\"\r\n",
    "    Iterate through ColData or Header.ColData data frame. \r\n",
    "    Check what kind of data each data frame contains.\r\n",
    "    Parse each record in data frame accordingly and return values.\r\n",
    "    \"\"\"\r\n",
    "    \r\n",
    "    # regular expression matching date format\r\n",
    "    date_rex = re.compile(\"^[0-9]{4}-[0-9]{2}-[0-9]{2}$\")\r\n",
    "\r\n",
    "    # check which ColData data frame is being parsed\r\n",
    "    for row in range(data.shape[0]):\r\n",
    "        # transaction detail data frame\r\n",
    "        if re.search(date_rex, data['value'][0]):\r\n",
    "            td   = data['value'][0]\r\n",
    "            tt   = data['value'][1]\r\n",
    "            ttid = data['id'][1]\r\n",
    "            dn   = data['value'][2]\r\n",
    "            vn   = data['value'][3]\r\n",
    "            vid  = data['id'][3]\r\n",
    "            m    = data['value'][4]\r\n",
    "            s    = data['value'][5]\r\n",
    "            sid  = data['id'][5]\r\n",
    "            ta   = data['value'][6]\r\n",
    "            nab  = data['value'][7]\r\n",
    "            \r\n",
    "            vals = {\r\n",
    "                'TransactionDate' : td,\r\n",
    "                'TransactionType' : tt,\r\n",
    "                'TransactionTypeID' : ttid,\r\n",
    "                'DocumentNumber' : dn,\r\n",
    "                'VendorName' : vn,\r\n",
    "                'VendorID' : vid,\r\n",
    "                'Memo' : m,\r\n",
    "                'Split' : s,\r\n",
    "                'SplitID' : sid,\r\n",
    "                'TransactionAmount' : ta,\r\n",
    "                'NewAccountBalance' : nab\r\n",
    "            }\r\n",
    "\r\n",
    "            # replace missing values           \r\n",
    "            for k in vals:\r\n",
    "                if not vals[k]:\r\n",
    "                    vals[k] = \"NA\"\r\n",
    "            \r\n",
    "            return vals\r\n",
    "\r\n",
    "        # beginning balance data frame\r\n",
    "        elif data['value'][0] == \"Beginning Balance\":\r\n",
    "            bb   = data['value'][7]\r\n",
    "            return {\r\n",
    "                'BeginningBalance' : bb\r\n",
    "            }\r\n",
    "\r\n",
    "        # name data frame\r\n",
    "        else:\r\n",
    "            if 'id' in data:\r\n",
    "                an  = data['value'][0]\r\n",
    "                aid = data['id'][0]\r\n",
    "            else:\r\n",
    "                an  = data['value'][0]\r\n",
    "                aid = \"NA\"\r\n",
    "                \r\n",
    "            return {\r\n",
    "                'AccountName' : an,\r\n",
    "                'AccountID' : aid\r\n",
    "            } \r\n",
    "\r\n",
    "acc_name_id = {}\r\n",
    "\r\n",
    "def json_crawler_gl(data):\r\n",
    "    # initialize global COUNT\r\n",
    "    # global count\r\n",
    "    global acc_name_id\r\n",
    "\r\n",
    "    # If data is dictionary returned by json.load(), then flatten it to initial pandas data frame\r\n",
    "    if isinstance(data, dict):\r\n",
    "        data = pd.json_normalize(data)\r\n",
    "        return_value = json_crawler_gl(data)\r\n",
    "        return return_value \r\n",
    "    \r\n",
    "    # Crawl through JSON file, normalizing by different keys to find account data and save to lst\r\n",
    "    else:\r\n",
    "        # Initialize list to hold account data objects\r\n",
    "        lst = []\r\n",
    "        \r\n",
    "        for row in range(data.shape[0]):\r\n",
    "            # Normalize by 'Header.ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['Header.ColData'][row])\r\n",
    "                lst.append(parse_record_gl(record_data))\r\n",
    "                # count += 1\r\n",
    "                acc_name_id = parse_record_gl(record_data)\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'ColData'\r\n",
    "            try:\r\n",
    "                record_data = pd.json_normalize(data['ColData'][row])\r\n",
    "                lst.append(parse_record_gl(record_data))\r\n",
    "                # lst[count].update(parse_record_gl(record_data))\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            # Normalize by 'Rows.Row'\r\n",
    "            try:\r\n",
    "                row_data = pd.json_normalize(data['Rows.Row'][row])\r\n",
    "                # Capture lst and return value before recursive function call\r\n",
    "                return_value = json_crawler_gl(row_data)\r\n",
    "                lst = lst + return_value\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "\r\n",
    "        return lst"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "list_df_csv(json_crawler_gl(general_ledger), \"C:\\\\Users\\\\paulcassidy\\\\OneDrive - Archdiocese of Chicago\\\\Documents\\\\JSON_Parsing\\\\Output\", \"test_gl_1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## going to have to do a thing with levels  \r\n",
    "structure:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "row = {\r\n",
    "    'AccountType' : at,\r\n",
    "    'AccountLevel1' : al1,\r\n",
    "    'AccountLevel1ID' : al1id,\r\n",
    "    'AccountLevel2' : al2,\r\n",
    "    'AccountLevel2ID' : al2id,\r\n",
    "    'AccountLevel3' : al3,\r\n",
    "    'AccountLevel3ID' : al3id,\r\n",
    "    'BeginningBalance' : bb,\r\n",
    "    'TransactionDate' : td,\r\n",
    "    'TransactionType' : tt,\r\n",
    "    'TransactionTypeID' : ttid,\r\n",
    "    'DocumentNumber' : dn,\r\n",
    "    'VendorName' : vn,\r\n",
    "    'VendorID' : vid,\r\n",
    "    'Memo' : m,\r\n",
    "    'Split' : s,\r\n",
    "    'SplitID' : sid,\r\n",
    "    'TransactionAmount' : ta,\r\n",
    "    'NewAccountBalance' : nab\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# import pandas module for data frame\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# Create dataframe for student data in different colleges\r\n",
    "subjectsdata = {'Name': ['sravan', 'sravan', 'sravan', 'sravan',\r\n",
    "\t\t\t\t\t\t'sravan', 'sravan', 'sravan', 'sravan',\r\n",
    "\t\t\t\t\t\t'Ojaswi', 'Ojaswi', 'Ojaswi', 'Ojaswi',\r\n",
    "\t\t\t\t\t\t'Ojaswi', 'Ojaswi', 'Ojaswi', 'Ojaswi',\r\n",
    "\t\t\t\t\t\t'Rohith', 'Rohith', 'Rohith', 'Rohith',\r\n",
    "\t\t\t\t\t\t'Rohith', 'Rohith', 'Rohith', 'Rohith'],\r\n",
    "\t\t\t\t\r\n",
    "\t\t\t\t'college': ['VFSTRU', 'VFSTRU', 'VFSTRU', 'VFSTRU',\r\n",
    "\t\t\t\t\t\t\t'VFSTRU', 'VFSTRU', 'VFSTRU', 'VFSTRU',\r\n",
    "\t\t\t\t\t\t\t'VIT', 'VIT', 'VIT', 'VIT', 'VIT', 'VIT',\r\n",
    "\t\t\t\t\t\t\t'VIT', 'VIT', 'IIT-Bhu', 'IIT-Bhu', 'IIT-Bhu',\r\n",
    "\t\t\t\t\t\t\t'IIT-Bhu', 'IIT-Bhu', 'IIT-Bhu', 'IIT-Bhu',\r\n",
    "\t\t\t\t\t\t\t'IIT-Bhu'],\r\n",
    "\t\t\t\t\r\n",
    "\t\t\t\t'subject': ['java', 'dbms', 'dms', 'coa', 'python', 'dld',\r\n",
    "\t\t\t\t\t\t\t'android', 'iot', 'java', 'dbms', 'dms', 'coa',\r\n",
    "\t\t\t\t\t\t\t'python', 'dld', 'android', 'iot', 'java',\r\n",
    "\t\t\t\t\t\t\t'dbms', 'dms', 'coa', 'python', 'dld', 'android',\r\n",
    "\t\t\t\t\t\t\t'iot']\r\n",
    "\t\t\t\t}\r\n",
    "\r\n",
    "# Convert into data frame\r\n",
    "df = pd.DataFrame(subjectsdata)\r\n",
    "\r\n",
    "# print the data(student records)\r\n",
    "print(df)\r\n",
    "\r\n",
    "# Set the hierarchical index\r\n",
    "df = df.set_index(['Name', 'college'], drop=False)\r\n",
    "\r\n",
    "# # print data frame\r\n",
    "# df\r\n",
    "\r\n",
    "# # setting index\r\n",
    "# df = df.set_index(['Name', 'college'])\r\n",
    "\r\n",
    "# # print data frame\r\n",
    "# df\r\n",
    "\r\n",
    "\r\n",
    "df.to_csv(\"C:\\\\Users\\\\paulcassidy\\\\OneDrive - Archdiocese of Chicago\\\\Documents\\\\JSON_Parsing\\\\Output\\\\hierarchy.csv\", index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Name  college  subject\n",
      "0   sravan   VFSTRU     java\n",
      "1   sravan   VFSTRU     dbms\n",
      "2   sravan   VFSTRU      dms\n",
      "3   sravan   VFSTRU      coa\n",
      "4   sravan   VFSTRU   python\n",
      "5   sravan   VFSTRU      dld\n",
      "6   sravan   VFSTRU  android\n",
      "7   sravan   VFSTRU      iot\n",
      "8   Ojaswi      VIT     java\n",
      "9   Ojaswi      VIT     dbms\n",
      "10  Ojaswi      VIT      dms\n",
      "11  Ojaswi      VIT      coa\n",
      "12  Ojaswi      VIT   python\n",
      "13  Ojaswi      VIT      dld\n",
      "14  Ojaswi      VIT  android\n",
      "15  Ojaswi      VIT      iot\n",
      "16  Rohith  IIT-Bhu     java\n",
      "17  Rohith  IIT-Bhu     dbms\n",
      "18  Rohith  IIT-Bhu      dms\n",
      "19  Rohith  IIT-Bhu      coa\n",
      "20  Rohith  IIT-Bhu   python\n",
      "21  Rohith  IIT-Bhu      dld\n",
      "22  Rohith  IIT-Bhu  android\n",
      "23  Rohith  IIT-Bhu      iot\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}